{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqYlSwYtS3Fs"
   },
   "source": [
    "# Sentimental Analysis -- BERT  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdJJ7FlPS3Fw"
   },
   "source": [
    "#### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4t2PENFTlcF4"
   },
   "outputs": [],
   "source": [
    "! pip install tensorflow_hub\n",
    "! pip install transformers\n",
    "! pip install keras tf-models-official #pydot graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgHEeI5Gloqj",
    "outputId": "a33d45fe-db44-4d0b-820a-146793755b7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.6.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "          tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "d2li-mj5lqhh",
    "outputId": "9fbd23cc-bae4-4c4d-d0c3-c205dfec1a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_path = './IMDB Dataset.csv'\n",
    "df = pd.read_csv(df_path)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "1jqnoryDlv3W",
    "outputId": "91a963f0-9225-4097-9be9-03df2d489913"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = df.sentiment.unique()\n",
    "counts = []\n",
    "\n",
    "for i in classes:\n",
    "    count = len(df[df.sentiment==i])\n",
    "    counts.append(count)\n",
    "\n",
    "plt.bar(['negative', 'positive'], counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "F-vACLgelyN0"
   },
   "outputs": [],
   "source": [
    "sample_size = int(len(df)*0.05)\n",
    "sampleDf = df.sample(sample_size, random_state=23)\n",
    "x = sampleDf.review.values\n",
    "y = sampleDf.sentiment.values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NZLEtx4ul8Iz"
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y_test = encoder.transform(y_test)\n",
    "encoded_Y_train = encoder.transform(y_train)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_test = np_utils.to_categorical(encoded_Y_test)\n",
    "dummy_y_train = np_utils.to_categorical(encoded_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bemt9WWgmGRF",
    "outputId": "8cadbf03-17ec-449c-d48a-7819068ef233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,) (500,)\n",
      "(500, 2) (2000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_Y_train.shape , encoded_Y_test.shape)\n",
    "print(dummy_y_test.shape , dummy_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wxsMW7AZmJkh"
   },
   "outputs": [],
   "source": [
    "########## We might want to use encoding for later. For that we can save enconding map.\n",
    "\n",
    "# os.mkdir('/content/model')\n",
    "# encoder_fname = 'encodings.npy'\n",
    "# my_wd = '/content/model'\n",
    "# np.save(os.path.join(my_wd, encoder_fname) , encoder.classes_)\n",
    "\n",
    "########## To load it when we'll use this in production just use the below cell (uncommented ofcourse)\n",
    "# encoder = LabelEncoder()\n",
    "# encoder.classes_ = np.load(os.path.join(my_wd, encoder_fname), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Hu_9kdP8mVHv"
   },
   "outputs": [],
   "source": [
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/2\",trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xphp0lzXm12P"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6723808dccb4276905efcc7b783f68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faad4fb5e0ba40f883958d71f703e98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589a073b62c04b53a452d55a1203c1cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/972k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831fae4ffa484df3a1a06c4ffb8366c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.87M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "\n",
    "# import official.nlp.bert.tokenization as tokenization\n",
    "# tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "# model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model_name ='bert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# to save tokenizer \n",
    "# tokenizer.save_pretrained('tokenizer')\n",
    "# to load from saved path\n",
    "# tokenizer = AutoTokenizer.from_pretrained('./tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_QyKfgJDm62t",
    "outputId": "b310ff26-46b6-47c5-fd43-c013ee7ba547"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (760 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized texts shape [2000, None]\n"
     ]
    }
   ],
   "source": [
    "def encode_names(n):\n",
    "    tokens = list(tokenizer.tokenize(n))\n",
    "    tokens.append('[SEP]')  # seperation token. Would bemuch more useful if you had a multiple text input.\n",
    "    return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "texts = tf.ragged.constant([\n",
    "    encode_names(n) for n in x_train])\n",
    "\n",
    "print('Tokenized texts shape', texts.shape.as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tCzVOaFym-ks"
   },
   "outputs": [],
   "source": [
    "cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*texts.shape[0]\n",
    "input_word_ids = tf.concat([cls, texts], axis=-1)\n",
    "\n",
    "input_mask = tf.ones_like(input_word_ids).to_tensor()\n",
    "\n",
    "\n",
    "\n",
    "type_cls = tf.zeros_like(cls)\n",
    "type_tweet = tf.ones_like(texts)\n",
    "input_type_ids = tf.concat([type_cls, type_tweet], axis=-1).to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQtO0pkPnXR3",
    "outputId": "cdc3c1fe-477d-4aad-949a-f01008a312ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length is: 1640\n",
      "Max length is: 2460\n"
     ]
    }
   ],
   "source": [
    "lens = [len(i) for i in input_word_ids]\n",
    "\n",
    "max_seq_length = max(lens)\n",
    "print('Max length is:', max_seq_length)\n",
    "max_seq_length  = int(1.5*max_seq_length)\n",
    "print('Max length is:', max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "j0g3vXRjnvIW"
   },
   "outputs": [],
   "source": [
    "def encode_names(n, tokenizer):\n",
    "    tokens = list(tokenizer.tokenize(n))\n",
    "    tokens.append('[SEP]')\n",
    "    return tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "def bert_encode(string_list, tokenizer, max_seq_length):\n",
    "    num_examples = len(string_list)\n",
    "\n",
    "    string_tokens = tf.ragged.constant([\n",
    "      encode_names(n, tokenizer) for n in np.array(string_list)])\n",
    "\n",
    "    cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*string_tokens.shape[0]\n",
    "    input_word_ids = tf.concat([cls, string_tokens], axis=-1)\n",
    "\n",
    "    input_mask = tf.ones_like(input_word_ids).to_tensor(shape=(None, max_seq_length))\n",
    "\n",
    "    type_cls = tf.zeros_like(cls)\n",
    "    type_tokens = tf.ones_like(string_tokens)\n",
    "    input_type_ids = tf.concat(\n",
    "      [type_cls, type_tokens], axis=-1).to_tensor(shape=(None, max_seq_length))\n",
    "\n",
    "    inputs = {\n",
    "      'input_word_ids': input_word_ids.to_tensor(shape=(None, max_seq_length)),\n",
    "      'input_mask': input_mask,\n",
    "      'input_type_ids': input_type_ids}\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JKrd_N9dn0XZ"
   },
   "outputs": [],
   "source": [
    "max_seq_length = 512\n",
    "X_train = bert_encode(x_train, tokenizer, max_seq_length)\n",
    "X_test = bert_encode(x_test, tokenizer, max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2cWCUyl2n11b"
   },
   "outputs": [],
   "source": [
    "num_class = len(encoder.classes_)  # Based on available class selection\n",
    "max_seq_length = max_seq_length  # we calculated this a couple cells ago\n",
    "\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                       name=\"input_word_ids\")\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                   name=\"input_mask\")\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                    name=\"segment_ids\")\n",
    "\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])                                  \n",
    "\n",
    "output = tf.keras.layers.Dropout(rate=0.1)(pooled_output)\n",
    "\n",
    "output = tf.keras.layers.Dense(num_class, activation='softmax', name='output')(output)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs={\n",
    "        'input_word_ids': input_word_ids,\n",
    "        'input_mask': input_mask,\n",
    "        'input_type_ids': segment_ids\n",
    "        },\n",
    "        outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Krhs9v4vn3sW"
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "batch_size = 4  # select based on your GPU resources\n",
    "eval_batch_size = batch_size\n",
    "\n",
    "train_data_size = len(dummy_y_train)\n",
    "steps_per_epoch = int(train_data_size / batch_size)\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "warmup_steps = int(epochs * train_data_size * 0.1 / batch_size)\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(\n",
    "#     learning_rate=2e-5, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "#     name='Adam'\n",
    "# )\n",
    "\n",
    "# from official import nlp\n",
    "# optimizer = nlp.optimization.create_optimizer(\n",
    "#     2e-5, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JUuzAU0uoAML"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cp7QMf9MoB54",
    "outputId": "802497a8-c6f3-4bfd-97e6-b46e8b57c188"
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "                    dummy_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_test, dummy_y_test),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qB0VRKboEJ1",
    "outputId": "071e1129-0e03-4c9e-971b-373f145de75f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9825\n",
      "Testing Accuracy:  0.8820\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, dummy_y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, dummy_y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert-sentiment-analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
